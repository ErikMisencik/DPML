=== Training Information ===
Objective: The agents aim to maximize territory gain.
Policy Name           : New_M_2_Q-Learning_MonteCarlo
Partial Observability : False
Number of Episodes    : 10000
Max Steps per Episode : 350

=== Training Parameters ===
Learning Rate         : 0.0025
Discount Factor       : 0.99
Initial Epsilon       : 1.0
Final Epsilon         : 1.0
Epsilon Decay Rate    : 0.9992
Minimum Epsilon       : 0.05
Epsilon Reset Every   : 5000 episodes
Epsilon Reset Value   : 0.5

=== Agent-Specific Information ===
Agent 0 (QLAgent):
  - Avg Cumulative Reward : 1171.76
  - Wins                  : 4919
  - Eliminations          : 2681
  - Self-Eliminations     : 173821
  - Color Assigned        : Indigo
  - Loaded Q-Table Path   : None (Training from scratch)

Agent 1 (MCAgent):
  - Avg Cumulative Reward : 1235.02
  - Wins                  : 5081
  - Eliminations          : 2774
  - Self-Eliminations     : 172954
  - Color Assigned        : Brown
  - Loaded Q-Table Path   : None (Training from scratch)

=== Reward Information ===
Self elimination penalty : -500
Trail reward             : 50
Max trail reward         : 300
Territory capture reward per cell: 50
Max trail length         : 12
Long trail penalty       : -200
Opponent elimination reward: 100
Opponent elimination penalty: -50
Enemy territory capture reward per cell: 30
Territory loss penalty per cell: -50
Reward survival percentage: 0.7
