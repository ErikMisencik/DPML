=== Training Information ===
Objective: The agents aim to maximize territory gain.
Policy Name           : New_M_2_Q-Learning_SARSA
Partial Observability : False
Number of Episodes    : 10000
Max Steps per Episode : 350

=== Training Parameters ===
Learning Rate         : 0.0025
Discount Factor       : 0.99
Initial Epsilon       : 1.0
Final Epsilon         : 1.0
Epsilon Decay Rate    : 0.9992
Minimum Epsilon       : 0.05
Epsilon Reset Every   : 5000 episodes
Epsilon Reset Value   : 0.5

=== Agent-Specific Information ===
Agent 0 (QLAgent):
  - Avg Cumulative Reward : 1254.16
  - Wins                  : 4411
  - Eliminations          : 5501
  - Self-Eliminations     : 172687
  - Color Assigned        : Orange
  - Loaded Q-Table Path   : None (Training from scratch)

Agent 1 (SARSAAgent):
  - Avg Cumulative Reward : 5628.18
  - Wins                  : 5589
  - Eliminations          : 3209
  - Self-Eliminations     : 86760
  - Color Assigned        : Pink
  - Loaded Q-Table Path   : None (Training from scratch)

=== Reward Information ===
Self elimination penalty : -500
Trail reward             : 50
Max trail reward         : 300
Territory capture reward per cell: 50
Max trail length         : 12
Long trail penalty       : -200
Opponent elimination reward: 100
Opponent elimination penalty: -50
Enemy territory capture reward per cell: 30
Territory loss penalty per cell: -50
Reward survival percentage: 0.7
