=== Q-Learning Training Information ===
Objective: The agent aims to maximize territory gain.
Policy Name           : q_learning
Partial observability : False
Number of Episodes    : 15000
Max Steps per Ep.     : 350
Learning Rate         : 0.0025
Discount Factor       : 0.99
Initial Epsilon       : 1.0
Final Epsilon         : 0.4996
Epsilon Decay Rate    : 0.9992
Minimum Epsilon       : 0.05
Epsilon Reset Every   : 5000 episodes
Epsilon Reset Value   : 0.5

=== Agent Statistics ===
Agent 0:
  - Total Wins           : 2424
  - Total Eliminations   : 8065
  - Total Self-Eliminations : 257909
  - Avg Cumulative Reward : -710.93

Agent 1:
  - Total Wins           : 2518
  - Total Eliminations   : 8085
  - Total Self-Eliminations : 257829
  - Avg Cumulative Reward : -713.11

Agent 2:
  - Total Wins           : 10058
  - Total Eliminations   : 9219
  - Total Self-Eliminations : 120048
  - Avg Cumulative Reward : 911.08

Agent Colors (Names): Indigo, Purple, Blue
Final Q-Table Path  : models\New_M_3_QLAgent_1\trained_model\q_table_ag_2_end.pkl

=== Reward Information ===
Self elimination penalty: -500
Trail reward        : 20
Max trail reward    : 80
Territory capture reward per cell: 30
Max trail length    : 12
Long trail penalty  : -100
Opponent elimination reward: 100
Opponent elimination penalty: -50
Enemy territory capture reward per cell: 30
Territory loss penalty per cell: -50
Reward survival percentage: 0.7
