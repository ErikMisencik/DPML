=== Training Information ===
Trained Date         : 04.03.2025
Trained Time         : 217.57 minutes

Objective: The agents aim to maximize territory gain.
Policy Name           : New_M_3_Q-Learning_SARSA_TD
Partial Observability : False
Number of Episodes    : 10000
Max Steps per Episode : 350

=== Training Parameters ===
Learning Rate         : 0.01
Discount Factor       : 0.99
Initial Epsilon       : 1.0
Final Epsilon         : 1.0
Epsilon Decay Rate    : 0.9997
Minimum Epsilon       : 0.1
Epsilon Reset Every   : N/A episodes
Epsilon Reset Value   : N/A

=== Agent-Specific Information ===
Agent 0 (QLAgent):
  - Avg Cumulative Reward : 187.10
  - Wins                  : 2403
  - Eliminations          : 5809
  - Self-Eliminations     : 86494
  - Color Assigned        : Red
  - Loaded Q-Table Path   : None (Training from scratch)

Agent 1 (SARSAAgent):
  - Avg Cumulative Reward : 581.46
  - Wins                  : 5385
  - Eliminations          : 5198
  - Self-Eliminations     : 43162
  - Color Assigned        : Purple
  - Loaded Q-Table Path   : None (Training from scratch)

Agent 2 (TDAgent):
  - Avg Cumulative Reward : 312.17
  - Wins                  : 2213
  - Eliminations          : 6900
  - Self-Eliminations     : 104466
  - Color Assigned        : Indigo
  - Loaded Q-Table Path   : None (Training from scratch)

=== Reward Information ===
Self elimination penalty : -150
Camping penalty          : False
Max camping penalty per episode: 30
Trail reward             : 5
Max trail reward count   : 7
Max trail length         : 10
Long trail penalty       : -5
Distance penalty factor  : 0.3
Opponent elimination reward: 300
Opponent elimination penalty: -100
Enemy territory capture reward per cell: 30
Territory loss penalty per cell: -20
Elimination reward modifier: 0.4
Territory capture reward per cell: 30
Shaping return bonus     : 20
Shaping distance factor  : 2
Expansion bonus          : 20
Expansion interval       : 50
Expansion growth threshold: 1
Exploration reward       : 1
