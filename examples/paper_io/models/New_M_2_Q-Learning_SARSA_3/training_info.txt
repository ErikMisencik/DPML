=== Training Information ===
Objective: The agents aim to maximize territory gain.
Policy Name           : New_M_2_Q-Learning_SARSA
Partial Observability : False
Number of Episodes    : 15000
Max Steps per Episode : 350

=== Training Parameters ===
Learning Rate         : 0.0025
Discount Factor       : 0.99
Initial Epsilon       : 1.0
Final Epsilon         : 1.0
Epsilon Decay Rate    : 0.9992
Minimum Epsilon       : 0.05
Epsilon Reset Every   : 5000 episodes
Epsilon Reset Value   : 0.5

=== Agent-Specific Information ===
Agent 0 (QLAgent):
  - Avg Cumulative Reward : 1235.35
  - Wins                  : 8077
  - Eliminations          : 10285
  - Self-Eliminations     : 263536
  - Color Assigned        : Green
  - Loaded Q-Table Path   : None (Training from scratch)

Agent 1 (SARSAAgent):
  - Avg Cumulative Reward : 2629.29
  - Wins                  : 6923
  - Eliminations          : 4865
  - Self-Eliminations     : 122649
  - Color Assigned        : Blue
  - Loaded Q-Table Path   : None (Training from scratch)

=== Reward Information ===
Self elimination penalty : -500
Trail reward             : 50
Max trail reward         : 300
Territory capture reward per cell: 50
Max trail length         : 12
Long trail penalty       : -200
Opponent elimination reward: 100
Opponent elimination penalty: -50
Enemy territory capture reward per cell: 30
Territory loss penalty per cell: -50
Reward survival percentage: 0.7
